{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30a487",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# imports -------------------------------------------------------------------------#\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np \n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "from ema import EMA\n",
    "from datasets import MnistDataset\n",
    "from transforms import RandomRotation\n",
    "from models.modelM3 import ModelM3\n",
    "from models.modelM5 import ModelM5\n",
    "from models.modelM7 import ModelM7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b019298",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run(p_seed=0, p_epochs=150, p_kernel_size=5, p_logdir=\"temp\"):\n",
    "    # random number generator seed ------------------------------------------------#\n",
    "    SEED = p_seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    # kernel size of model --------------------------------------------------------#\n",
    "    KERNEL_SIZE = p_kernel_size\n",
    "\n",
    "    # number of epochs ------------------------------------------------------------#\n",
    "    NUM_EPOCHS = p_epochs\n",
    "\n",
    "    # file names ------------------------------------------------------------------#\n",
    "    if not os.path.exists(\"../logs/%s\"%p_logdir):\n",
    "        os.makedirs(\"../logs/%s\"%p_logdir)\n",
    "    OUTPUT_FILE = str(\"../logs/%s/log%03d.out\"%(p_logdir,SEED))\n",
    "    MODEL_FILE = str(\"../logs/%s/model%03d.pth\"%(p_logdir,SEED))\n",
    "\n",
    "    # enable GPU usage ------------------------------------------------------------#\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda == False:\n",
    "        print(\"WARNING: CPU will be used for training.\")\n",
    "        exit(0)\n",
    "\n",
    "    # data augmentation methods ---------------------------------------------------#\n",
    "    transform = transforms.Compose([\n",
    "        RandomRotation(20, seed=SEED),\n",
    "        transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
    "        ])\n",
    "\n",
    "    # data loader -----------------------------------------------------------------#\n",
    "    train_dataset = MnistDataset(training=True, transform=transform)\n",
    "    test_dataset = MnistDataset(training=False, transform=None)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=120, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    # model selection -------------------------------------------------------------#\n",
    "    if(KERNEL_SIZE == 3):\n",
    "        model = ModelM3().to(device)\n",
    "    elif(KERNEL_SIZE == 5):\n",
    "        model = ModelM5().to(device)\n",
    "    elif(KERNEL_SIZE == 7):\n",
    "        model = ModelM7().to(device)\n",
    "\n",
    "    summary(model, (1, 28, 28))\n",
    "\n",
    "    # hyperparameter selection ----------------------------------------------------#\n",
    "    ema = EMA(model, decay=0.999)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "\n",
    "    # delete result file ----------------------------------------------------------#\n",
    "    f = open(OUTPUT_FILE, 'w')\n",
    "    f.close()\n",
    "\n",
    "    # global variables ------------------------------------------------------------#\n",
    "    g_step = 0\n",
    "    max_correct = 0\n",
    "\n",
    "    # training and evaluation loop ------------------------------------------------#\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        #--------------------------------------------------------------------------#\n",
    "        # train process                                                            #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_corr = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device, dtype=torch.int64)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            train_pred = output.argmax(dim=1, keepdim=True)\n",
    "            train_corr += train_pred.eq(target.view_as(train_pred)).sum().item()\n",
    "            train_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            g_step += 1\n",
    "            ema(model, g_step)\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{:05d}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = 100 * train_corr / len(train_loader.dataset)\n",
    "\n",
    "        #--------------------------------------------------------------------------#\n",
    "        # test process                                                             #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        model.eval()\n",
    "        ema.assign(model)\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total_pred = np.zeros(0)\n",
    "        total_target = np.zeros(0)\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device,  dtype=torch.int64)\n",
    "                output = model(data)\n",
    "                test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                total_pred = np.append(total_pred, pred.cpu().numpy())\n",
    "                total_target = np.append(total_target, target.cpu().numpy())\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            if(max_correct < correct):\n",
    "                torch.save(model.state_dict(), MODEL_FILE)\n",
    "                max_correct = correct\n",
    "                print(\"Best accuracy! correct images: %5d\"%correct)\n",
    "        ema.resume(model)\n",
    "\n",
    "        #--------------------------------------------------------------------------#\n",
    "        # output                                                                   #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
    "        best_test_accuracy = 100 * max_correct / len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%) (best: {:.2f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset), test_accuracy, best_test_accuracy))\n",
    "\n",
    "        f = open(OUTPUT_FILE, 'a')\n",
    "        f.write(\" %3d %12.6f %9.3f %12.6f %9.3f %9.3f\\n\"%(epoch, train_loss, train_accuracy, test_loss, test_accuracy, best_test_accuracy))\n",
    "        f.close()\n",
    "\n",
    "        #--------------------------------------------------------------------------#\n",
    "        # update learning rate scheduler                                           #\n",
    "        #--------------------------------------------------------------------------#\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f41bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--seed\", default=0, type=int)\n",
    "    p.add_argument(\"--trials\", default=15, type=int)\n",
    "    p.add_argument(\"--epochs\", default=150, type=int)    \n",
    "    p.add_argument(\"--kernel_size\", default=5, type=int)    \n",
    "    p.add_argument(\"--gpu\", default=0, type=int)\n",
    "    p.add_argument(\"--logdir\", default=\"temp\")\n",
    "    args = p.parse_args()\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(args.gpu)\n",
    "    for i in range(args.trials):\n",
    "        run(p_seed = args.seed + i,\n",
    "            p_epochs = args.epochs,\n",
    "            p_kernel_size = args.kernel_size,\n",
    "            p_logdir = args.logdir)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
